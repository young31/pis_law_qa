# AI 법률 질의응답 시스템 사용자 가이드

**최종 업데이트: 2025년 5월 18일**

## 0. 개요
- 해당 코드 및 파일은 일부 전처리를 제외하고는 vibe coding 으로 작성되었습니다. 
- local 환경에서 정보 유출 없이 사용하고자 개발되었으며, python 및 ollama 를 위한 환경 구축 후 사용할 수 있습니다.

## 1. 소개

AI 법률 질의응답 시스템에 오신 것을 환영합니다! 이 시스템은 사용자가 업로드한 법률 문서 및 기존 질의응답(Q&A) 데이터를 기반으로 법률 관련 질문에 답변을 생성하는 인공지능 어시스턴트입니다. 사용자는 다양한 설정을 통해 시스템의 답변 생성 방식을 최적화할 수 있습니다.

**주요 기능:**
* PDF 및 TXT 형식의 법률 문서 로드 및 분석
* Excel 파일 형식의 기존 Q&A 데이터 통합
* Ollama 및 Google GenAI 임베딩 모델 선택 가능
* Ollama 기반 LLM을 통한 답변 생성
* 세 가지 답변 모드 제공:
    * **RAG (문서 기반):** 업로드된 문서 내용을 기반으로 답변
    * **Blended (RAG + LLM 개선):** RAG 답변을 LLM이 한 번 더 개선 ★★★
    * **LLM 직접 답변:** LLM 자체 지식으로 답변 (문서 참조 안 함)

## 2. 시스템 요구사항 및 초기 설정

**사용자/관리자를 위한 참고사항:**

* **Python 환경:** 시스템 실행을 위해 Python 및 필요한 라이브러리(Streamlit, pandas, LangChain 등)가 설치되어 있어야 합니다.
    ```bash
    pip install streamlit pandas openpyxl langchain langchain-chroma langchain-google-genai langchain-ollama langchain-community python-dotenv
    ```
* **Ollama (로컬 LLM/임베딩 사용 시):**
    * Ollama 서버가 실행 중이어야 합니다.
    * 사이드바에서 선택할 Ollama 모델(예: `mxbai-embed-large` 임베딩 모델, `phi4-mini` LLM)이 Ollama에 다운로드되어 있어야 합니다. (예: `ollama pull phi4-mini`)
* **Google API Key (Google 임베딩 사용 시):**
    * Google Generative AI API 키가 필요합니다. 애플리케이션 폴더에 `.env` 파일을 만들고 다음과 같이 키를 추가하세요:
        ```
        GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY_HERE"
        ```
* **법률 문서 폴더:**
    * 기본적으로 애플리케이션은 `./laws_data_streamlit_app` 폴더에서 법률 문서를 찾습니다. 이 폴더를 만들고 분석할 PDF 또는 TXT 파일을 넣어두세요. 폴더 경로는 사이드바에서 변경할 수 있습니다.

* **Q&A Excel 파일 형식:**
    * 참고할 Q&A 데이터는 Excel 파일(`.xlsx`, `.xls`)로 준비합니다.
    * 파일에는 최소한 "질문"(또는 "Question", "질의") 컬럼과 "답변"(또는 "Answer", "응답") 컬럼이 있어야 합니다. 다른 추가 정보 컬럼도 포함될 수 있습니다.

## 3. 애플리케이션 실행

터미널 또는 명령 프롬프트에서 애플리케이션 `app.py` 파일이 있는 폴더로 이동한 후 다음 명령어를 실행합니다:
```bash
streamlit run app.py
```

웹 브라우저에서 애플리케이션이 자동으로 열립니다.

## 4. 사용자 인터페이스 개요
애플리케이션은 크게 **사이드바 (설정 영역)**와 **메인 영역 (데이터베이스 관리 및 질의응답)**으로 나뉩니다.

### 4.1. 사이드바 (⚙️ 시스템 설정)
사이드바에서는 시스템의 작동 방식을 제어하는 다양한 설정을 변경할 수 있습니다.
1. 법률 문서 로딩:문서 디렉토리: 법률 문서(PDF, TXT)가 저장된 폴더 경로를 지정합니다.문서 타입: 로드할 법률 문서의 파일 형식을 선택합니다 (txt 또는 pdf).

2. 임베딩 모델: 문서 내용을 벡터로 변환하여 검색 가능하게 만드는 모델을 선택합니다.

    - 제공자: "Ollama" (로컬 모델) 또는 "Google" (클라우드 기반 모델) 중에서 선택합니다.Ollama 모델명: Ollama 사용 시 임베딩 모델명을 입력합니다. (예: mxbai-embed-large)
    - Google 모델명: Google 사용 시 임베딩 모델명을 입력합니다. (예: models/embedding-001). Google API 키가 필요합니다.

3. LLM (답변 생성): 실제 답변을 생성하는 대규모 언어 모델(LLM)을 설정합니다. 
    - Ollama LLM 모델명: 답변 생성에 사용할 Ollama LLM 모델명을 입력합니다. (예: phi4-mini)

4. 벡터 DB 설정: 문서를 검색 가능한 형태로 저장하는 방식(벡터 데이터베이스)을 설정합니다.
    -  Chunk Size: 문서를 분할하는 단위 크기입니다. 너무 작으면 맥락이 부족하고, 너무 크면 관련 없는 정보가 많아질 수 있습니다.
    - Chunk Overlap: 분할된 조각(Chunk)들이 서로 겹치는 글자 수입니다. 맥락 유지를 돕습니다.

5. 이전 Q&A 데이터 (선택):
    - Q&A 참고자료 Excel 파일 업로드: 기존 질의응답 기록이 담긴 Excel 파일을 업로드합니다. 이 데이터는 법률 문서와 함께 답변 생성 시 참고 자료로 활용됩니다.
       - Question, Asnwer 컬럼으로 지정하여 업로드
    - DB 강제 재생성: 이 옵션을 선택하고 "DB 준비" 버튼을 누르면, 기존에 저장된 벡터 데이터베이스를 삭제하고 모든 문서를 처음부터 다시 처리하여 새로운 데이터베이스를 생성합니다. 다음과 같은 경우에 유용합니다:
        - 법률 문서나 Q&A Excel 파일의 내용이 크게 변경되었을 때DB 관련 문제가 의심될 때
        - 임베딩 모델이나 청크 설정 변경 후 확실하게 새 DB를 만들고 싶을 때

### 4.2. 메인 영역
💾 데이터베이스 관리:
- 상태 메시지: 현재 데이터베이스(DB)의 상태를 보여줍니다. (예: "DB가 로드되지 않았습니다.", "DB 준비 완료")

- "로드 및 DB 준비" 버튼: 사이드바에서 설정한 내용(문서 경로, 모델, Q&A 파일 등)을 바탕으로 문서를 로드하고, 처리한 후 벡터 데이터베이스를 생성하거나 기존 DB를 로드합니다. 설정을 변경하거나 새 문서를 추가/수정한 후에는 반드시 이 버튼을 눌러 DB를 최신 상태로 만들어야 합니다.💬 

💬 질의응답:
답변 방식 선택:
- RAG (문서 기반): 준비된 데이터베이스(법률 문서, Q&A 데이터)에서 관련 내용을 검색하여 답변을 생성합니다.

- Blended (RAG + LLM 개선): RAG 방식으로 생성된 초기 답변을 LLM이 한 번 더 검토하고 개선하여 최종 답변을 만듭니다. 더 자연스럽고 포괄적인 답변을 기대할 수 있습니다.

- LLM 직접 답변: 데이터베이스를 참조하지 않고, 설정된 LLM의 일반 지식만을 사용하여 답변합니다.질문 입력: 여기에 법률 관련 질문을 입력합니다.답변 생성 🚀 버튼: 질문 입력 후 이 버튼을 누르면 AI가 답변 생성을 시작합니다.

결과 표시:
- 🤖 AI 답변: 생성된 답변 내용이 표시됩니다.

- 📚 참고 문헌 (검색된 문서): 
    - RAG 또는 Blended 모드 사용 시, 답변 생성에 참고한 문서 조각(법률 문서 또는 Q&A)의 출처와 내용을 확인할 수 있습니다. 각 항목을 클릭하여 펼쳐볼 수 있습니다.

## 5. 단계별 사용 가이드

### 5.1. 초기 설정 및 첫 사용 
**사이드바 설정**:
1. 법률 문서 로딩에서 법률 문서가 있는 폴더 경로와 파일 타입을 지정합니다.
2. 임베딩 모델에서 사용할 임베딩 모델 제공자와 모델명을 선택/입력합니다. (Google 선택 시 API 키 확인)
3. LLM (답변 생성)에서 사용할 Ollama LLM 모델명을 입력합니다.
4. 벡터 DB 설정에서 Chunk Size와 Overlap을 필요에 따라 조정합니다. (기본값 사용 가능) 
5. (선택 사항)이전 Q&A 데이터에서 참고할 Q&A Excel 파일을 업로드합니다.

**데이터베이스 준비**:

메인 영역의 💾 데이터베이스 관리 섹션에서 "로드 및 DB 준비" 버튼을 클릭합니다.문서 로딩, 처리, 임베딩, DB 생성 과정이 진행되며, 다소 시간이 소요될 수 있습니다. (특히 처음 실행 시 또는 "DB 강제 재생성" 선택 시)상태 메시지가 "✅ DB 준비 완료..."로 변경되면 다음 단계로 진행할 수 있습니다.LLM 모델도 자동으로 로드되며, 사이드바 하단에 로드 상태가 표시됩니다.

### 5.2. 질문하기
DB 및 LLM 상태 확인: 
데이터베이스가 준비되고 LLM이 성공적으로 로드되었는지 확인합니다. (사이드바 하단 및 DB 관리 섹션 상태 메시지 참고)

답변 방식 선택: 
💬 질의응답 섹션에서 원하는 답변 방식을 선택합니다.

질문 입력: 텍스트 영역에 질문을 입력합니다.

답변 생성: "답변 생성 🚀" 버튼을 클릭합니다.결과 확인: 잠시 후 AI 답변과 참고 문헌(해당 시)이 표시됩니다.

### 5.3. 데이터 또는 설정 업데이트 시 
법률 문서 변경/추가 또는 Q&A 파일 변경/업데이트 시:
- 변경된 문서를 지정된 폴더에 반영하거나, 새 Q&A Excel 파일을 업로드합니다.

- 데이터 변경이 크거나 확실한 반영을 원하면 사이드바에서 "DB 강제 재생성" 옵션을 체크합니다."로드 및 DB 준비" 버튼을 다시 클릭하여 데이터베이스를 업데이트합니다.

임베딩 모델, LLM 모델, 또는 Chunk 설정 변경 시:
- 사이드바에서 원하는 설정을 변경합니다."로드 및 DB 준비" 버튼을 클릭합니다. (이전 설정과 다른 DB가 생성되거나 로드됩니다. 확실한 변경을 위해 "DB 강제 재생성"을 함께 사용하는 것이 좋습니다.)

## 6. 문제 해결 / FAQ
"LLM 로드 실패" 메시지가 표시될 경우:
- Ollama를 사용하는 경우, Ollama 서버가 실행 중인지, 선택한 LLM 모델명이 정확하고 다운로드되어 있는지 확인하세요.네트워크 연결 상태를 확인하세요.

"DB 준비 실패" 또는 문서 로드 오류 메시지가 표시될 경우:
- 사이드바에 지정된 '문서 디렉토리' 경로가 정확한지, 해당 폴더에 접근 권한이 있는지 확인하세요.
- 선택한 '문서 타입'과 실제 파일 형식이 일치하는지 확인하세요.
- Q&A Excel 파일의 형식이 올바른지, 필요한 "질문", "답변" 컬럼이 있는지 확인하세요.
- 선택한 임베딩 모델이 정상적으로 접근 가능한지 확인하세요. (예: Google API 키 유효성, Ollama 모델 상태)
- 디스크 공간이 충분한지 확인하세요.

"GOOGLE_API_KEY 없음" 경고 (Google 임베딩 사용 시):
- 애플리케이션 폴더에 .env 파일이 있고, 그 안에 GOOGLE_API_KEY="YOUR_KEY" 형식으로 API 키가 올바르게 입력되어 있는지 확인하세요.

답변이 느리거나 시스템이 느리게 반응할 경우:
- 문서의 크기나 개수가 매우 많거나, Q&A 데이터가 방대할 경우 초기 DB 생성 및 검색에 시간이 더 소요될 수 있습니다.선택한 Ollama 모델(특히 LLM)이 고사양을 요구하는 모델일 수 있습니다. 더 가벼운 모델로 변경해 보세요.

답변이 만족스럽지 않거나 관련 없는 내용이 나올 경우:
- 질문을 더 명확하고 구체적으로 작성해 보세요.DB에 포함된 법률 문서의 품질과 내용을 확인하세요.
- Q&A 데이터가 현재 질문과 관련성이 높은지 확인하세요.
- 사이드바의 'Chunk Size' 및 'Chunk Overlap' 설정을 조정해 보세요. (변경 후 DB 재준비 필요)
- 다른 답변 모드(예: Blended)를 사용해 보세요.

## 7. 최상의 결과 얻기 위한 팁
고품질 데이터 사용: 
깨끗하고 정확한 법률 문서와 Q&A 데이터를 사용하세요.

적절한 설정 실험: 
문서의 특성에 맞게 Chunk Size/Overlap을 조정해 보세요.

모델 선택: 사용 가능한 하드웨어와 원하는 답변 품질에 맞춰 Ollama 모델을 선택하세요.

명확한 질문: 구체적이고 명확한 질문이 더 좋은 답변을 유도합니다.

"DB 강제 재생성" 활용: 데이터 소스가 크게 변경되거나 문제가 있을 때 주저하지 말고 사용하세요.

---
이 가이드가 AI 법률 질의응답 시스템을 효과적으로 사용하는 데 도움이 되기를 바랍니다.
